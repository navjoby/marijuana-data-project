{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZCItt6y2t4L"
      },
      "source": [
        "# CS105 Final Project \n",
        "- completed by Naveen Joby, Apar Mistry, and Arhum Shahid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l85mM7xYihqG"
      },
      "source": [
        "This project aims to analyze marijuana arrests within the City of Los Angeles, dating from 2010 onwards. We plan to use pearsonâ€™s correlation, and k-nearest neighbors to find correlations between age, sex, race (descent code), and area (based off the 21 Community Police Stations). We would also like to try and figure out charges based on sex, age, and area. Moreover, based on certain ages and locations, we can try and see if certain areas are more likely for a specific crime related to marijuana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Y72edQT721rA",
        "outputId": "2d0d364d-14ce-4eac-fafd-c2ce0482cce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas_bokeh\n",
            "  Downloading pandas_bokeh-0.5.5-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: bokeh>=2.0 in /usr/local/lib/python3.7/dist-packages (from pandas_bokeh) (2.3.3)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from pandas_bokeh) (1.3.5)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (3.13)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (21.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas_bokeh) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=2.0->pandas_bokeh) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=2.0->pandas_bokeh) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->pandas_bokeh) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=2.0->pandas_bokeh) (1.15.0)\n",
            "Installing collected packages: pandas-bokeh\n",
            "Successfully installed pandas-bokeh-0.5.5\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cc1e30ede151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_bokeh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mbasedf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Marijuana_Data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mbasedf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Marijuana_Data.csv'"
          ]
        }
      ],
      "source": [
        "#$python3 install pandas-bokeh\n",
        "\n",
        "%pip install pandas_bokeh\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pandas_bokeh\n",
        "\n",
        "basedf = pd.read_csv('./Marijuana_Data.csv')\n",
        "basedf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ycqru8VNOq"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KQSihYu37H9"
      },
      "source": [
        "**Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW-zFO2j4GDd"
      },
      "outputs": [],
      "source": [
        "#removing space from column names\n",
        "basedf = basedf.rename(columns={\"Report ID\": \"ReportID\", \"Sex Code\": \"SexCode\",\n",
        "                                 \"Arrest Date\": \"ArrestDate\", \"Area ID\": \"AreaID\", \"Reporting District\": \"ReportingDistrict\", \"Descent Code\": \"DescentCode\", \"Charge Description\": \"ChargeDescription\"})\n",
        "basedf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naS68VdX4TwF"
      },
      "source": [
        "**Gender and Age Distribution in Each Area**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGwCCX-g4cN3"
      },
      "outputs": [],
      "source": [
        "newtable = pd.crosstab(basedf['AreaID'], basedf['SexCode'])\n",
        "newtable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q55qCQV24kP4"
      },
      "outputs": [],
      "source": [
        "newtable.plot.bar(stacked=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iubyCrRfhsIa"
      },
      "source": [
        "With this visualization, we notice that a staggering amount of the arestees are male across the 21 police stations. However, this doesn't grant us a lot of information about arrest data. Based of a quick Google search, the ratio of male to female is about 97 men : 100 women. So, the copius amounts of men being arrested isn't because there is a higher population of men in LA than women. Do men tend to possess more marijuana than women? Is it easier for women to get out of arrests than men? Without other information regarding these specific arrests (which is difficult to find due to privacy laws), we cannot make a conclusive analylsis about the gender ratio in marijuana arrests. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEUkmolJlpSF"
      },
      "source": [
        "Now, we can look at the age correlation with data. The data includes people as young as 11, all the way to 79. Since there's such a high amount of ages, we decided to group it using a AgeCode instead.\n",
        "Anyone less than 18 would have a code of 1, 18-30 would be 2, 31-40 would be 3,41-50 would be 4, 51-60 would be 5, 61-70 would be 6, and anything older would be 7. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpOA5MxXlhDS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "basedf['AgeCode'] = 0\n",
        "for ind in basedf.index:\n",
        "     if(basedf['Age'][ind] < 18):\n",
        "         basedf['AgeCode'][ind] = 1\n",
        "     elif(basedf['Age'][ind] >= 18 and basedf['Age'][ind] < 30):\n",
        "         basedf['AgeCode'][ind] = 2\n",
        "     elif(basedf['Age'][ind] >= 30 and basedf['Age'][ind] < 40):\n",
        "         basedf['AgeCode'][ind] = 3\n",
        "     elif(basedf['Age'][ind] >= 40 and basedf['Age'][ind] < 50):\n",
        "         basedf['AgeCode'][ind] = 4\n",
        "     elif(basedf['Age'][ind] >= 50 and basedf['Age'][ind] < 60):\n",
        "         basedf['AgeCode'][ind] = 5\n",
        "     elif(basedf['Age'][ind] >= 60 and basedf['Age'][ind] < 70):\n",
        "         basedf['AgeCode'][ind] = 6\n",
        "     else:\n",
        "         basedf['AgeCode'][ind] = 7\n",
        "newtable = pd.crosstab(basedf['AreaID'], basedf['AgeCode'])\n",
        "newtable.plot.bar(stacked=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE3j-24KUpaH"
      },
      "source": [
        "As we can see in the visualization above, age code 2, which is from 18-30, seems to be the most common age for arrestees in all 21 police stations. To add, the second most common age seems to be 31-40, which is age code 3. This makes sense, as the people who tend to use marijuana products (and thereby get arrested for them) are usually in these age groups. There is also a small percentage of all the other age codes, the least common ones being age codes 6 and 7. This makes sense because people aged > 61 are very unlikely to get arrested for marijuana possession. Another thing that we noticed is how people younger than 18 tended to get arrested for marijuana related crimes. Although we did notice that there were arestees as young as 11 and 12, We didn't expect a huge amount of minors to be indicted for marijuana charges. \n",
        "\n",
        "Next, we will look at the relationship between the area and decent code for the arrestees. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t33iPgmP4vg1"
      },
      "source": [
        "**Descent Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUuTirXhnk7y"
      },
      "outputs": [],
      "source": [
        "# pandas_bokeh.output_notebook()\n",
        "# RaceTab = pd.crosstab(basedf['DescentCode'], basedf['AreaID'])\n",
        "# RaceTab.plot.bar(stacked=True).legend(loc= 'best')\n",
        "#max_elements.plot.bar()\n",
        "\n",
        "newtable = pd.crosstab(basedf['AreaID'], basedf['DescentCode'])\n",
        "newtable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Iq9jdbS3anq"
      },
      "source": [
        "This table shows the descent code categorization by each Area code. The LA county race categorization is one that doesn't make much sense. \n",
        "\n",
        "\n",
        "The categories are as follows:\n",
        "\n",
        "A - Other Asian B - Black C - Chinese D - Cambodian F - Filipino G - Guamanian H - Hispanic/Latin/Mexican I - American Indian/Alaskan Native J - Japanese K - Korean L - Laotian O - Other P - Pacific Islander S - Samoan U - Hawaiian V - Vietnamese W - White X - Unknown Z - Asian Indian\n",
        "\n",
        "So, we decided to group up Asian countries. Now, they have a tag for A - Asian. We also decided to group together Samoa (S) and Hawaii (U) with Pacific Islanders (P). Our new grouping would be:\n",
        "\n",
        "A - Asian, B - Black, G - Guamanian, H - Hispanic/Latin/Mexican, I - American Indian/Alaskan Native, O - Other, P - Pacific Islander, W - White, X - Unknown "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99RIi0_L2RER"
      },
      "outputs": [],
      "source": [
        "# use pie chart, easier to explain why we're disregarding the other races (so small that it won't matter)\n",
        "basedf['RaceCode'] = 0\n",
        "for ind in basedf.index:\n",
        "     # asian countries\n",
        "     if(basedf['DescentCode'][ind] == 'C'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     elif(basedf['DescentCode'][ind] == 'D'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     elif(basedf['DescentCode'][ind] == 'F'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     elif(basedf['DescentCode'][ind] == 'J'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     elif(basedf['DescentCode'][ind] == 'K'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     elif(basedf['DescentCode'][ind] == 'L'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     elif(basedf['DescentCode'][ind] == 'V'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     elif(basedf['DescentCode'][ind] == 'Z'):\n",
        "         basedf['RaceCode'][ind] = 'A'\n",
        "     # pacific islander\n",
        "     elif(basedf['DescentCode'][ind] == 'S'):\n",
        "         basedf['RaceCode'][ind] = 'P'\n",
        "     elif(basedf['DescentCode'][ind] == 'U'):\n",
        "         basedf['RaceCode'][ind] = 'P'\n",
        "     else:\n",
        "        basedf['RaceCode'][ind] = basedf['DescentCode'][ind]\n",
        "\n",
        "explode = [0, 0, 0, 0, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "basedf['RaceCode'].value_counts().plot.pie(explode = explode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAoJh-yM0K50"
      },
      "source": [
        "This pie chart shows the percentages of different races that were arrested for marijuana related crimes. As shown in the chart, hispanic/latin/mexican arrests(H) and black arrests (B) made up a huge portion of the pie, well over 2/3. White (W) arrests and others (O) also made a sizable portion. Since many Asian countries had very little amount of arrestees, we chose to group all of the Asian countries under \"A,\" and it was still nearly impossible to see anything in the visualization because of such low percentages. We did the same grouping for Pacific Islanders, grouping Samoa and Hawaii. Once again, it was still nearly impossible to see in the visualization. This data doesn't really show us much, but provides insight as to what trends we can view."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1mkwsSx308y"
      },
      "source": [
        "**KNN-Predicting Charge Based off of Area Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEU4m_cmv1mP"
      },
      "source": [
        "With this dataset, our primary goal was to see if certain areas are more likely for a specific crime related to marijuana. Although all the detainees were arrested due to marijuana related crimes, not all of the charges are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imk-hPiJ342i"
      },
      "outputs": [],
      "source": [
        "basedf['ChargeDescription'].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-aJukt1bal"
      },
      "source": [
        "The first 10 charge descriptions show varying charges for each person. This allows us to perform KNN to try and classify what charge a person would most likely be convicted of based on each area of the 21 Community Police Stations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPFKylwe61Le"
      },
      "source": [
        "First, we want to do some data cleaning. There are a couple of rows in which there are no charge descriptions. Since these values cannot be used (as they'll affect the outcome), we decided to change all of these values to \"Marijuana Related Crimes\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEiGWfum60Wk"
      },
      "outputs": [],
      "source": [
        "change = ['ChargeDescription']\n",
        "\n",
        "for column in change:\n",
        "  basedf[column] = basedf[column].replace(np.NaN, \"Marijuana Related Crimes\")\n",
        "\n",
        "print(basedf['ChargeDescription'])  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB_XUSuT_hKa"
      },
      "source": [
        "Now, we want to change these descriptions to numbers so that we can perform KNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeOv5UIZ_gqK"
      },
      "outputs": [],
      "source": [
        "basedf['ChargeCode'] = 0\n",
        "for ind in basedf.index:\n",
        "     # asian countries\n",
        "     if(basedf['ChargeDescription'][ind] == \"POSSESS MARIJUANA FOR SALE\"):\n",
        "         basedf['ChargeCode'][ind] = '1'\n",
        "     elif(basedf['ChargeDescription'][ind] == \"SALE/OFFER TO SELL/TRANSPORT MARIJUANA\"):\n",
        "         basedf['ChargeCode'][ind] = '2'\n",
        "     elif(basedf['ChargeDescription'][ind] == \"TRANSPORT/SELL/FURNISH/ETC MARIJUANA\"):\n",
        "         basedf['ChargeCode'][ind] = '3'\n",
        "     elif(basedf['ChargeDescription'][ind] == \"SMOKE/INGEST MARIJUANA IN PUBLIC PLACE\"):\n",
        "         basedf['ChargeCode'][ind] = '4'\n",
        "    \n",
        "    # FINISH THE REST\n",
        "\n",
        "     else:\n",
        "         basedf['ChargeCode'][ind] = '-1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn9MUc88Ea7V"
      },
      "outputs": [],
      "source": [
        "basedf.head(20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FinalProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
